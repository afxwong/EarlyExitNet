{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: numpy in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.26.0)\n",
      "Requirement already satisfied: pandas in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.8.0)\n",
      "Requirement already satisfied: datasets in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (2.14.5)\n",
      "Requirement already satisfied: filelock in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
      "Requirement already satisfied: requests in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from torchvision->-r requirements.txt (line 2)) (10.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (0.17.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from datasets->-r requirements.txt (line 7)) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.11/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Is CUDA available? False\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Check for CUDA support\n",
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which model to load\n",
    "model_name = \"resnet\" # either \"resnet\" or \"vgg\"\n",
    "\n",
    "model_path = os.path.join(\"models\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EarlyExitModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): OptionalExitModule(\n",
       "      (module): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (exit_gate): Linear(in_features=200704, out_features=1, bias=True)\n",
       "      (classifier): Linear(in_features=200704, out_features=10, bias=True)\n",
       "    )\n",
       "    (layer2): OptionalExitModule(\n",
       "      (module): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (exit_gate): Linear(in_features=802816, out_features=1, bias=True)\n",
       "      (classifier): Linear(in_features=802816, out_features=10, bias=True)\n",
       "    )\n",
       "    (layer3): OptionalExitModule(\n",
       "      (module): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (exit_gate): Linear(in_features=401408, out_features=1, bias=True)\n",
       "      (classifier): Linear(in_features=401408, out_features=10, bias=True)\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EarlyExitModel import EarlyExitModel\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# Load the model (classifiers trained, but no gates)\n",
    "# Need a custom unpickler to load the model onto the CPU since it was trained on a GPU and dumped, not saved\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "# Load the model onto the CPU\n",
    "f = open(os.path.join(model_path, \"final_classifier.pkl\"), \"rb\")\n",
    "model = CPU_Unpickler(f).load()\n",
    "\n",
    "# Set the device on the model and its submodules\n",
    "model.device = device    \n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from DataLoader import CustomDataset\n",
    "\n",
    "if model_name == \"resnet\":\n",
    "    # use the imagenette dataset\n",
    "    hf_dataset = load_dataset(\"frgfm/imagenette\", '320px')\n",
    "    hf_dataset = concatenate_datasets(hf_dataset.values())\n",
    "elif model_name == \"vgg\":\n",
    "    # use the cifar10 dataset\n",
    "    hf_dataset = load_dataset(\"cifar10\")\n",
    "    hf_dataset = concatenate_datasets(hf_dataset.values())\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "torch_dataset = CustomDataset(hf_dataset, transform=transform)\n",
    "\n",
    "batch_size = 32 if model_name == \"resnet\" else 64\n",
    "\n",
    "test_size = 0.2\n",
    "test_volume = int(test_size * len(torch_dataset))\n",
    "train_volume = len(torch_dataset) - test_volume\n",
    "\n",
    "train_dataset, test_dataset = random_split(torch_dataset, [train_volume, test_volume])\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Exit Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want tensorboard support, you need to run the following commands on **macOS**:\n",
    "\n",
    "This clears your logs:\n",
    "```\n",
    "rm -rf runs/*\n",
    "```\n",
    "\n",
    "This shows your public IP address:\n",
    "```\n",
    "dig -4 TXT +short o-o.myaddr.l.google.com @ns1.google.com\n",
    "```\n",
    "\n",
    "This starts tensorboard at this address:\n",
    "```\n",
    "tensorboard --host 0.0.0.0 --logdir={model_path}/runs\n",
    "```\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want tensorboard support, you need to run the following commands on **Windows**:\n",
    "\n",
    "This clears your logs:\n",
    "```\n",
    "rmdir /s /q runs\n",
    "```\n",
    "\n",
    "This shows your IP address:\n",
    "```\n",
    "powershell -command \"$ipAddress = (Invoke-WebRequest -Uri 'http://ipinfo.io/ip').Content.Trim(); Write-Host 'Your IP address is: ' $ipAddress\"  \n",
    "```\n",
    "\n",
    "This starts tensorboard at this address:\n",
    "```\n",
    "tensorboard --host 0.0.0.0 --logdir={model_path}\\runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EarlyExitTrainer import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(model, device, model_dir=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with alpha=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                   | 0/168 [00:11<?, ?it/s, Loss=7.28]"
     ]
    }
   ],
   "source": [
    "# train the exits\n",
    "alpha_range = [i / 100.0 for i in range(0, 101, 5)]\n",
    "\n",
    "accuracies = {}\n",
    "times = {}\n",
    "avg_exit_idx = {}\n",
    "\n",
    "for alpha in alpha_range:\n",
    "    print(f\"Training with alpha={alpha}\")\n",
    "    trainer.set_alpha(alpha)\n",
    "    final_accuracy, final_time, final_avg_exit_idx = trainer.train_exit_layers(train_dataloader, epoch_count=5, validation_loader=test_dataloader)\n",
    "    \n",
    "    # write statistics\n",
    "    accuracies[alpha] = final_accuracy\n",
    "    times[alpha] = final_time\n",
    "    avg_exit_idx[alpha] = final_avg_exit_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# generate dataframe containing statistics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"alpha\": alpha_range,\n",
    "    \"accuracy\": accuracies,\n",
    "    \"time\": times,\n",
    "    \"avg_exit_idx\": avg_exit_idx\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "\n",
    "df.to_csv(os.path.join(model_path, \"alpha_tuning.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
