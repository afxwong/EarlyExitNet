{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# %pip install -r requirements.txt\n",
    "import warnings\n",
    "\n",
    "# ignore FutureWarning\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.0\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Is CUDA available? False\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Check for CUDA support\n",
    "print(f\"Is CUDA available? {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which model to load\n",
    "model_name = \"densenet_cifar100\" # either \"resnet\" or \"vgg_cifar10\" or \"vgg_cifar100\"\n",
    "num_classes = 100 if \"cifar100\" in model_name else 10\n",
    "model_path = os.path.join(\"models\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from DataLoader import CustomDataset\n",
    "\n",
    "def create_dataloader(test_batch_size=None):\n",
    "    if model_name == \"resnet\":\n",
    "        # use the imagenette dataset\n",
    "        hf_dataset = load_dataset(\"frgfm/imagenette\", '320px')\n",
    "        hf_dataset = concatenate_datasets(hf_dataset.values())\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    elif model_name == \"vgg_cifar10\":\n",
    "        # use the cifar10 dataset\n",
    "        hf_dataset = load_dataset(\"cifar10\")\n",
    "        hf_dataset = concatenate_datasets(hf_dataset.values())\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.507, 0.4865, 0.4409],\n",
    "                                std=[0.2673, 0.2564, 0.2761])\n",
    "        ])\n",
    "    elif \"cifar100\" in model_name:\n",
    "        # use the cifar100 dataset\n",
    "        hf_dataset = load_dataset(\"cifar100\")\n",
    "        hf_dataset = concatenate_datasets(hf_dataset.values())\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "    torch_dataset = CustomDataset(hf_dataset, transform=transform)\n",
    "\n",
    "    batch_size = 32 if model_name == \"resnet\" else 64\n",
    "\n",
    "    test_size = 0.2\n",
    "    test_volume = int(test_size * len(torch_dataset))\n",
    "    train_volume = len(torch_dataset) - test_volume\n",
    "\n",
    "    train_dataset, test_dataset = random_split(torch_dataset, [train_volume, test_volume])\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False, \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    if test_batch_size is None:\n",
    "        test_batch_size = batch_size\n",
    "        \n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, torch_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Exit Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from OptionalExitModule import TrainingState\n",
    "import datetime\n",
    "\n",
    "def collect_val_data(num_batches=50, num_runs=4, should_print=True):\n",
    "    model.eval()\n",
    "    \n",
    "    # throw away the first run\n",
    "    if should_print:\n",
    "        print(\"Throwing away the first run...\")\n",
    "        collect_val_data(num_batches=num_batches, num_runs=1, should_print=False)\n",
    "    \n",
    "    print(f\"Collecting data for {num_batches if num_batches is not None else 'all'} batches {num_runs} times...\")\n",
    "    average_times = []\n",
    "    average_accs = []\n",
    "    for _ in range(num_runs):\n",
    "        # iterate through the entire dataloader and save the exit idxs\n",
    "        exit_idx_counts = {}\n",
    "        times = []\n",
    "        adj_times = []\n",
    "        accs = []\n",
    "        for i, (x, y) in enumerate(test_dataloader):\n",
    "            x = x.to(device)\n",
    "            start = time.time()\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            accs.append((torch.argmax(y_hat, dim=1) == y.to(device)).sum().item() / len(y))\n",
    "            times.append(time.time() - start)\n",
    "            adj_times.append(times[-1] - sum([exit_module.gate_time for exit_module in model.exit_modules]))\n",
    "            \n",
    "            y_hat_classes = y_hat.argmax(dim=1)\n",
    "            exit_idxs = torch.tensor(model.num_exits_per_module, device=device)\n",
    "            for (j, exit_idx) in enumerate(exit_idxs):\n",
    "                exit_idx_counts[j+1] = exit_idx_counts.get(j+1, 0) + exit_idx.item()\n",
    "                \n",
    "            if i+1 == num_batches: break\n",
    "            \n",
    "        average_times.append(np.array(times).mean())\n",
    "        average_accs.append(np.array(accs).mean())\n",
    "        \n",
    "        if not should_print: continue\n",
    "        print(datetime.datetime.now())\n",
    "        print(\"TIME\", average_times[-1])\n",
    "        print(\"ACCURACY\", average_accs[-1])\n",
    "        if adj_times[-1] > 0:\n",
    "            print(adj_times[-1])\n",
    "    \n",
    "    if not should_print: return   \n",
    "    print(exit_idx_counts)\n",
    "    print(f\"Average time: {np.array(average_times).mean()}\")\n",
    "    print(f\"Average accuracy: {np.array(average_accs).mean()}\")\n",
    "    return exit_idx_counts, average_times, average_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EarlyExit DenseNet121 model architecture...\n",
      "Adding exits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.8/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.8/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.8/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/Users/dylanmace/miniforge3/envs/earlyexit/lib/python3.8/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
     ]
    }
   ],
   "source": [
    "import ModelLoader\n",
    "\n",
    "train_dataloader, test_dataloader, _ = create_dataloader(test_batch_size=None)\n",
    "loader = ModelLoader.ModelLoader(model_name, device, alpha=0.55, dataloader=train_dataloader)\n",
    "\n",
    "# preview the model architecture\n",
    "model = loader.load_model(num_outputs=num_classes, pretrained=True)\n",
    "\n",
    "print(\"\\n=====================================================\\n\")\n",
    "with torch.no_grad():\n",
    "    ee_idxs, ee_times, ee_accs = collect_val_data(num_runs=5, num_batches=None)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, reload model with no exits and run testing again\n",
    "\n",
    "train_dataloader, test_dataloader, _ = create_dataloader(test_batch_size=None)\n",
    "loader = ModelLoader.ModelLoader(model_name, device, alpha=0.55, dataloader=train_dataloader)\n",
    "\n",
    "# preview the model architecture\n",
    "model = loader.load_model(num_outputs=num_classes, pretrained=True)\n",
    "model.clear_exits()\n",
    "print(\"\\n=====================================================\\n\")\n",
    "with torch.no_grad():\n",
    "    orig_idxs, orig_times, orig_accs = collect_val_data(num_runs=5, num_batches=None)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=====================================================\\n\")\n",
    "print(f\"Accuracy Drop: {np.array(orig_accs).mean() - np.array(ee_accs).mean()}\")\n",
    "print(f\"Speedup Factor: {np.array(orig_times).mean() / np.array(ee_times).mean()}x\")\n",
    "print(f\"Exit Index Distribution: {ee_idxs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "  \n",
    "if \"cifar100\" in model_name:\n",
    "    class_names = [\n",
    "        \"apple\",\n",
    "        \"aquarium_fish\",\n",
    "        \"baby\",\n",
    "        \"bear\",\n",
    "        \"beaver\",\n",
    "        \"bed\",\n",
    "        \"bee\",\n",
    "        \"beetle\",\n",
    "        \"bicycle\",\n",
    "        \"bottle\",\n",
    "        \"bowl\",\n",
    "        \"boy\",\n",
    "        \"bridge\",\n",
    "        \"bus\",\n",
    "        \"butterfly\",\n",
    "        \"camel\",\n",
    "        \"can\",\n",
    "        \"castle\",\n",
    "        \"caterpillar\",\n",
    "        \"cattle\",\n",
    "        \"chair\",\n",
    "        \"chimpanzee\",\n",
    "        \"clock\",\n",
    "        \"cloud\",\n",
    "        \"cockroach\",\n",
    "        \"couch\",\n",
    "        \"crab\",\n",
    "        \"crocodile\",\n",
    "        \"cup\",\n",
    "        \"dinosaur\",\n",
    "        \"dolphin\",\n",
    "        \"elephant\",\n",
    "        \"flatfish\",\n",
    "        \"forest\",\n",
    "        \"fox\",\n",
    "        \"girl\",\n",
    "        \"hamster\",\n",
    "        \"house\",\n",
    "        \"kangaroo\",\n",
    "        \"keyboard\",\n",
    "        \"lamp\",\n",
    "        \"lawn_mower\",\n",
    "        \"leopard\",\n",
    "        \"lion\",\n",
    "        \"lizard\",\n",
    "        \"lobster\",\n",
    "        \"man\",\n",
    "        \"maple_tree\",\n",
    "        \"motorcycle\",\n",
    "        \"mountain\",\n",
    "        \"mouse\",\n",
    "        \"mushroom\",\n",
    "        \"oak_tree\",\n",
    "        \"orange\",\n",
    "        \"orchid\",\n",
    "        \"otter\",\n",
    "        \"palm_tree\",\n",
    "        \"pear\",\n",
    "        \"pickup_truck\",\n",
    "        \"pine_tree\",\n",
    "        \"plain\",\n",
    "        \"plate\",\n",
    "        \"poppy\",\n",
    "        \"porcupine\",\n",
    "        \"possum\",\n",
    "        \"rabbit\",\n",
    "        \"raccoon\",\n",
    "        \"ray\",\n",
    "        \"road\",\n",
    "        \"rocket\",\n",
    "        \"rose\",\n",
    "        \"sea\",\n",
    "        \"seal\",\n",
    "        \"shark\",\n",
    "        \"shrew\",\n",
    "        \"skunk\",\n",
    "        \"skyscraper\",\n",
    "        \"snail\",\n",
    "        \"snake\",\n",
    "        \"spider\",\n",
    "        \"squirrel\",\n",
    "        \"streetcar\",\n",
    "        \"sunflower\",\n",
    "        \"sweet_pepper\",\n",
    "        \"table\",\n",
    "        \"tank\",\n",
    "        \"telephone\",\n",
    "        \"television\",\n",
    "        \"tiger\",\n",
    "        \"tractor\",\n",
    "        \"train\",\n",
    "        \"trout\",\n",
    "        \"tulip\",\n",
    "        \"turtle\",\n",
    "        \"wardrobe\",\n",
    "        \"whale\",\n",
    "        \"willow_tree\",\n",
    "        \"wolf\",\n",
    "        \"woman\",\n",
    "        \"worm\"\n",
    "    ]\n",
    "else:\n",
    "    class_names = []\n",
    "    \n",
    "if model_name == \"vgg_cifar10\":\n",
    "    class_idx = 5\n",
    "elif model_name == \"vgg_cifar100\" or model_name == \"densenet_cifar100\":\n",
    "    class_idx = class_names.index(\"apple\")\n",
    "else:\n",
    "    class_idx = 0\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the images of the class_idx\n",
    "_, _, torch_dataset = create_dataloader()\n",
    "\n",
    "class_images = []\n",
    "for i in range(len(torch_dataset)):\n",
    "    img, label = torch_dataset[i]\n",
    "    if label == class_idx:\n",
    "        class_images.append((img, label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(class_images)} images of class {class_names[class_idx]}\")\n",
    "print(f\"Shape of first image: {class_images[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each image throughout the model\n",
    "num_exits_taken = {}\n",
    "misclassified_images = {}\n",
    "correct_images = {}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(class_images)):\n",
    "    image, label = class_images[i]\n",
    "    image = image.reshape(1, *image.shape).to(device)\n",
    "    \n",
    "    output_class = model(image)\n",
    "    exit_idx_taken = torch.tensor(model.num_exits_per_module, device=device).argmax() + 1\n",
    "    num_exits_taken[exit_idx_taken.item()] = num_exits_taken.get(exit_idx_taken.item(), 0) + 1\n",
    "    \n",
    "    # get class name for prediction from model\n",
    "    class_idx_prediction = torch.argmax(output_class, dim=1).item()\n",
    "    class_name = class_names[class_idx_prediction]\n",
    "    \n",
    "    if output_class.argmax() != class_idx:\n",
    "        misclassified_images[i] = (class_name, label, exit_idx_taken.item())\n",
    "    else:\n",
    "        correct_images[i] = exit_idx_taken.item()\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f\"Processed {i} images:\", num_exits_taken)\n",
    "        print(f\"Misclassified images: {len(misclassified_images)}\")\n",
    "        print(f\"Correct images: {len(correct_images)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through correct and incorrect images to find where they exited\n",
    "exit_idxs_incorrect = {}\n",
    "for (_, _, exit_idx_taken) in misclassified_images.values():\n",
    "    exit_idxs_incorrect[exit_idx_taken] = exit_idxs_incorrect.get(exit_idx_taken, 0) + 1\n",
    "\n",
    "exit_idxs_correct = {}\n",
    "for idx in correct_images.values():\n",
    "    exit_idxs_correct[idx] = exit_idxs_correct.get(idx, 0) + 1\n",
    "\n",
    "\n",
    "print(\"Correct Indices\", exit_idxs_correct)\n",
    "print(\"Incorrect Indices\", exit_idxs_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data_vis\"):\n",
    "    os.mkdir(\"data_vis\")\n",
    "    \n",
    "if not os.path.exists(os.path.join(\"data_vis\", \"misclassified\")):\n",
    "    os.mkdir(os.path.join(\"data_vis\", \"misclassified\"))\n",
    "    \n",
    "if not os.path.exists(os.path.join(\"data_vis\", \"correct\")):\n",
    "    os.mkdir(os.path.join(\"data_vis\", \"correct\"))\n",
    "    \n",
    "# clear the folders\n",
    "for filename in os.listdir(os.path.join(\"data_vis\", \"misclassified\")):\n",
    "    os.remove(os.path.join(\"data_vis\", \"misclassified\", filename))\n",
    "    \n",
    "for filename in os.listdir(os.path.join(\"data_vis\", \"correct\")):\n",
    "    os.remove(os.path.join(\"data_vis\", \"correct\", filename))\n",
    "    \n",
    "# save the misclassified images\n",
    "for i, (label, y, exit_idx) in misclassified_images.items():\n",
    "    image = class_images[i][0]\n",
    "    torchvision.utils.save_image(image, os.path.join(\"data_vis\", \"misclassified\", f\"{i}-{label}-idx{exit_idx}.png\"))\n",
    "    \n",
    "# save the correct images\n",
    "for (image_idx, exit_idx) in correct_images.items():\n",
    "    image = class_images[image_idx][0]\n",
    "    torchvision.utils.save_image(image, os.path.join(\"data_vis\", \"correct\", f\"{image_idx}-idx{exit_idx}.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
